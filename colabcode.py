import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
mean = np.array([0.5, 0.5, 0.5])
std = np.array([0.25, 0.25, 0.25])
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
}
from google.colab import drive
drive.mount('/content/drive')
import os
import shutil
import pandas as pd
from sklearn.model_selection import train_test_split
from zipfile import ZipFile

# ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
csv_path = "/content/drive/MyDrive/labels_my-project-name_2025-10-26-09-30-18.csv"
df = pd.read_csv(csv_path, header=None)
df.columns = ["filename", "label"]

# ğŸ”¹ ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ []
df["label"] = df["label"].str.strip("[]")

# ğŸ”¹ ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
zip_path = "/content/drive/MyDrive/Photos.zip"
output_base = "data/hymenoptera_data"

with ZipFile(zip_path, 'r') as zip_ref:
    # ğŸ”¹ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù…ÙˆØ³ Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª Ø¯Ø§Ø®Ù„ ZIP
    zip_files = {os.path.basename(f): f for f in zip_ref.namelist()}

    # ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)

    def extract_images(dataframe, subset):
        for _, row in dataframe.iterrows():
            filename = row["filename"]
            label = row["label"]
            dst_dir = os.path.join(output_base, subset, label)
            os.makedirs(dst_dir, exist_ok=True)
            dst_path = os.path.join(dst_dir, filename)

            if filename in zip_files:
                with zip_ref.open(zip_files[filename]) as src_file, open(dst_path, 'wb') as dst_file:
                    shutil.copyfileobj(src_file, dst_file)
            else:
                print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ ZIP: {filename}")

    extract_images(train_df, "train")
    extract_images(val_df, "val")

print("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª train Ùˆ val Ø­Ø³Ø¨ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª.")
import os
import shutil
import pandas as pd
from sklearn.model_selection import train_test_split
from zipfile import ZipFile

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
import torchvision
import matplotlib.pyplot as plt
import numpy as np
import copy
import time

# =============================
# 1ï¸âƒ£ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV Ùˆ ZIP
# =============================

csv_path = "/content/drive/MyDrive/labels_my-project-name_2025-10-26-09-30-18.csv"
zip_path = "/content/drive/MyDrive/Photos.zip"
output_base = "data/hymenoptera_data"

# ØªØ­Ù…ÙŠÙ„ CSV
df = pd.read_csv(csv_path, header=None)
df.columns = ["filename", "label"]
df["label"] = df["label"].str.strip("[]")

# ÙÙƒ Ø¶ØºØ· Ø§Ù„ØµÙˆØ± Ù…Ù† ZIP Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª train/val Ø­Ø³Ø¨ CSV
with ZipFile(zip_path, 'r') as zip_ref:
    zip_files = {os.path.basename(f): f for f in zip_ref.namelist()}
    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)

    def extract_images(dataframe, subset):
        for _, row in dataframe.iterrows():
            filename = row["filename"]
            label = row["label"]
            dst_dir = os.path.join(output_base, subset, label)
            os.makedirs(dst_dir, exist_ok=True)
            dst_path = os.path.join(dst_dir, filename)

            if filename in zip_files:
                with zip_ref.open(zip_files[filename]) as src_file, open(dst_path, 'wb') as dst_file:
                    shutil.copyfileobj(src_file, dst_file)
            else:
                print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ ZIP: {filename}")

    extract_images(train_df, "train")
    extract_images(val_df, "val")

print("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª train Ùˆ val Ø­Ø³Ø¨ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª.")

# =============================
# 2ï¸âƒ£ ØªØ¬Ù‡ÙŠØ² Dataset Ùˆ DataLoader
# =============================

data_dir = output_base

data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          transform=data_transforms[x])
                  for x in ['train', 'val']}

dataloaders = {x: DataLoader(image_datasets[x], batch_size=32,
                             shuffle=True, num_workers=2)
               for x in ['train', 'val']}

dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# =============================
# 3ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
# =============================

def imshow(inp, title=None):
    """Ø¹Ø±Ø¶ ØµÙˆØ±Ø© Ù…Ù† Tensor"""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title:
        plt.title(title)
    plt.pause(0.001)

# Ø¹Ø±Ø¶ Batch Ù„Ù„ØªØ£ÙƒØ¯
inputs, classes = next(iter(dataloaders['train']))
out = torchvision.utils.make_grid(inputs)
imshow(out, title=[class_names[x] for x in classes])

# =============================
# 4ï¸âƒ£ Ø¯Ø§Ù„Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# =============================

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs_batch, labels in dataloaders[phase]:
                inputs_batch = inputs_batch.to(device)
                labels = labels.to(device)

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs_batch)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        optimizer.zero_grad()
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs_batch.size(0)
                running_corrects += torch.sum(preds == labels.data)

            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                phase, epoch_loss, epoch_acc))

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
        time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    model.load_state_dict(best_model_wts)
    return model

# =============================
# 5ï¸âƒ£ ConvNet as fixed feature extractor
# =============================

model_conv = models.resnet18(pretrained=True)
for param in model_conv.parameters():
    param.requires_grad = False  # ØªØ¬Ù…ÙŠØ¯ ÙƒÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª

num_ftrs = model_conv.fc.in_features
model_conv.fc = nn.Linear(num_ftrs, len(class_names))  # Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙÙ‚Ø· Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ù„Ù…
model_conv = model_conv.to(device)

criterion = nn.CrossEntropyLoss()
optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)
import torch
import torch.nn as nn
from torchvision import models

# Ù†ÙØªØ±Ø¶ Ø£Ù† model_conv Ù‡Ùˆ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¨Ø§Ù„ÙØ¹Ù„
# device Ù…Ø¹Ø±Ù Ù…Ø³Ø¨Ù‚Ù‹Ø§ (cuda Ø£Ùˆ cpu)
# class_names Ù…Ø¹Ø±Ù Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† ImageFolder

# =============================
# Ø­ÙØ¸ state_dict (Ø§Ù„Ù…Ø³ØªØ­Ø³Ù†)
# =============================
FILE_STATE = "model_conv_state.pth"
torch.save(model_conv.state_dict(), FILE_STATE)

# =============================
# Ù„ØªØ­Ù…ÙŠÙ„ state_dict Ù„Ø§Ø­Ù‚Ù‹Ø§
# =============================
# Ø¥Ù†Ø´Ø§Ø¡ Ù†ÙØ³ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_loaded = models.resnet18(pretrained=False)
num_ftrs = model_loaded.fc.in_features
model_loaded.fc = nn.Linear(num_ftrs, len(class_names))

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ state_dict
model_loaded.load_state_dict(torch.load(FILE_STATE, map_location=device))
model_loaded = model_loaded.to(device)
model_loaded.eval()  # ØªØ­ÙˆÙŠÙ„Ù‡ Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
import torch
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt

# =============================
# 1ï¸âƒ£ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
# =============================
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# =============================
# 2ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø©
# =============================
def predict_image(image_path, model, class_names):
    image = Image.open(image_path).convert('RGB')
    input_tensor = preprocess(image).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(input_tensor)
        _, pred = torch.max(output, 1)
        class_name = class_names[pred.item()]
    return image, class_name

# =============================
# 3ï¸âƒ£ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
# =============================
img_path = "/content/drive/MyDrive/mosque.jpeg"  
image, class_name = predict_image(img_path, model, class_names)

plt.imshow(image)
plt.title(f"Predection {class_name}")
plt.axis('off')
plt.show()
