ğŸ¤– Ø±ÙˆØ¨ÙˆØªÙƒ Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ â€“ Ù…Ø´Ø±ÙˆØ¹ ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„ÙŠÙ…Ù†ÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
ğŸ“– ÙÙƒØ±Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

ÙŠÙ‡Ø¯Ù Ù…Ø´Ø±ÙˆØ¹ Ø±ÙˆØ¨ÙˆØªÙƒ Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ ØªØµÙ†ÙŠÙ ØµÙˆØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠØ© ÙÙŠ Ø§Ù„ÙŠÙ…Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚.
ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£ÙŠ Ù…Ø¹Ù„Ù… Ø£Ø«Ø±ÙŠ Ø£Ùˆ Ø³ÙŠØ§Ø­ÙŠØŒ Ù„ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ØªØ­Ù„ÙŠÙ„Ù‡Ø§ ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ù„Ù… ÙˆØ¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø®ØªØµØ±Ø© Ø¹Ù†Ù‡.


Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€ Ø£ÙˆÙ„Ø§ ØªÙ… ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± ÙˆØ¹Ù…Ù„ labeling Ùˆ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¦ 3 classesÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€ 


ğŸ—ºï¸ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„ØªÙŠ ÙŠØªØ¹Ø±Ù Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

ÙŠØªØ¹Ø±Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ù…Ø¹Ø§Ù„Ù… ÙŠÙ…Ù†ÙŠØ© ØªØ§Ø±ÙŠØ®ÙŠØ© ÙˆØ³ÙŠØ§Ø­ÙŠØ©ØŒ Ù…Ù†Ù‡Ø§ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„:

ğŸ•Œ Alkabir_Mosque â€” Ø§Ù„Ù…Ø³Ø¬Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ± ÙÙŠ ØµÙ†Ø¹Ø§Ø¡ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©.

ğŸ° Sultan_Al_Kathiri_Palace â€” Ù‚ØµØ± Ø§Ù„Ø³Ù„Ø·Ø§Ù† Ø§Ù„ÙƒØ«ÙŠØ±ÙŠ ÙÙŠ Ø³ÙŠØ¦ÙˆÙ†.

ğŸ¡ Alhajareen â€”  Ø§Ù„Ù‡Ø¬Ø±ÙŠÙ† Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ.


(ÙˆÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø¨Ø³Ù‡ÙˆÙ„Ø© Ø¨Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.)

âš™ï¸ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
ğŸ§  1. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ResNet18 Ù…Ù† Ù…ÙƒØªØ¨Ø© PyTorch Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„ØªÙ†Ø§Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„ÙŠÙ…Ù†ÙŠØ©.

ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØ± Ù…ØµÙ†ÙØ© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª.

Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø£ÙˆØ²Ø§Ù† ÙÙŠ Ù…Ù„Ù:

model_conv_state.pth

ğŸŒ 2. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ÙˆÙŠØ¨ (Flask)

ØªØ·Ø¨ÙŠÙ‚ ÙˆÙŠØ¨ Ø¨Ø³ÙŠØ· ØªÙ… Ø¨Ù†Ø§Ø¤Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Flask.

ÙŠØ³Ù…Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø© Ù…Ù† Ø¬Ù‡Ø§Ø²Ù‡.

ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³Ù… Ø§Ù„Ù…Ø¹Ù„Ù… ÙˆØ¹Ø±Ø¶ ÙˆØµÙ Ù…ÙˆØ¬Ø² Ù„Ù‡ ÙÙŠ Ø§Ù„ØµÙØ­Ø©.

ğŸ§© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
Ø§Ù„Ù…Ù„Ù	Ø§Ù„ÙˆØµÙ
app.py	Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„ØªØ·Ø¨ÙŠÙ‚ Flask (ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… + ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬).
templates/index.html	ØµÙØ­Ø© Ø§Ù„ÙˆÙŠØ¨ Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø±ÙØ¹ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø®Ù„Ø§Ù„Ù‡Ø§.
model_conv_state.pth	Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„ÙŠÙ…Ù†ÙŠØ©.
train_model.ipynb	ÙƒÙˆØ¯ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Google Colab.
static/	Ù…Ø¬Ù„Ø¯ Ù„Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© Ù…Ø¤Ù‚ØªÙ‹Ø§.
ğŸš€ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ù…Ø­Ù„ÙŠÙ‹Ø§
ğŸ”¹ 1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
pip install flask torch torchvision pillow

ğŸ”¹ 2. Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

Ø¶Ø¹ Ø§Ù„Ù…Ù„Ù model_conv_state.pth ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ app.py.

ğŸ”¹ 3. ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
python app.py


Ø«Ù… Ø§ÙØªØ­ Ø§Ù„Ù…ØªØµÙØ­ Ø¹Ù„Ù‰:

http://127.0.0.1:5000

ğŸ§  Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©

Python ğŸ

Flask ğŸŒ

PyTorch ğŸ”¥

Torchvision

Pillow (PIL)

Google Colab 
ÙƒÙˆØ¯ Ø§Ù„ÙƒÙˆÙ„Ø§Ø¨ : 

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
mean = np.array([0.5, 0.5, 0.5])
std = np.array([0.25, 0.25, 0.25])
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
}
from google.colab import drive
drive.mount('/content/drive')
import os
import shutil
import pandas as pd
from sklearn.model_selection import train_test_split
from zipfile import ZipFile

# ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
csv_path = "/content/drive/MyDrive/labels_my-project-name_2025-10-26-09-30-18.csv"
df = pd.read_csv(csv_path, header=None)
df.columns = ["filename", "label"]

# ğŸ”¹ ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ []
df["label"] = df["label"].str.strip("[]")

# ğŸ”¹ ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
zip_path = "/content/drive/MyDrive/Photos.zip"
output_base = "data/hymenoptera_data"

with ZipFile(zip_path, 'r') as zip_ref:
    # ğŸ”¹ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù…ÙˆØ³ Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª Ø¯Ø§Ø®Ù„ ZIP
    zip_files = {os.path.basename(f): f for f in zip_ref.namelist()}

    # ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)

    def extract_images(dataframe, subset):
        for _, row in dataframe.iterrows():
            filename = row["filename"]
            label = row["label"]
            dst_dir = os.path.join(output_base, subset, label)
            os.makedirs(dst_dir, exist_ok=True)
            dst_path = os.path.join(dst_dir, filename)

            if filename in zip_files:
                with zip_ref.open(zip_files[filename]) as src_file, open(dst_path, 'wb') as dst_file:
                    shutil.copyfileobj(src_file, dst_file)
            else:
                print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ ZIP: {filename}")

    extract_images(train_df, "train")
    extract_images(val_df, "val")

print("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª train Ùˆ val Ø­Ø³Ø¨ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª.")
import os
import shutil
import pandas as pd
from sklearn.model_selection import train_test_split
from zipfile import ZipFile

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
import torchvision
import matplotlib.pyplot as plt
import numpy as np
import copy
import time

# =============================
# 1ï¸âƒ£ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV Ùˆ ZIP
# =============================

csv_path = "/content/drive/MyDrive/labels_my-project-name_2025-10-26-09-30-18.csv"
zip_path = "/content/drive/MyDrive/Photos.zip"
output_base = "data/hymenoptera_data"

# ØªØ­Ù…ÙŠÙ„ CSV
df = pd.read_csv(csv_path, header=None)
df.columns = ["filename", "label"]
df["label"] = df["label"].str.strip("[]")

# ÙÙƒ Ø¶ØºØ· Ø§Ù„ØµÙˆØ± Ù…Ù† ZIP Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª train/val Ø­Ø³Ø¨ CSV
with ZipFile(zip_path, 'r') as zip_ref:
    zip_files = {os.path.basename(f): f for f in zip_ref.namelist()}
    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)

    def extract_images(dataframe, subset):
        for _, row in dataframe.iterrows():
            filename = row["filename"]
            label = row["label"]
            dst_dir = os.path.join(output_base, subset, label)
            os.makedirs(dst_dir, exist_ok=True)
            dst_path = os.path.join(dst_dir, filename)

            if filename in zip_files:
                with zip_ref.open(zip_files[filename]) as src_file, open(dst_path, 'wb') as dst_file:
                    shutil.copyfileobj(src_file, dst_file)
            else:
                print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ ZIP: {filename}")

    extract_images(train_df, "train")
    extract_images(val_df, "val")

print("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª train Ùˆ val Ø­Ø³Ø¨ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª.")

# =============================
# 2ï¸âƒ£ ØªØ¬Ù‡ÙŠØ² Dataset Ùˆ DataLoader
# =============================

data_dir = output_base

data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          transform=data_transforms[x])
                  for x in ['train', 'val']}

dataloaders = {x: DataLoader(image_datasets[x], batch_size=32,
                             shuffle=True, num_workers=2)
               for x in ['train', 'val']}

dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# =============================
# 3ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
# =============================

def imshow(inp, title=None):
    """Ø¹Ø±Ø¶ ØµÙˆØ±Ø© Ù…Ù† Tensor"""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title:
        plt.title(title)
    plt.pause(0.001)

# Ø¹Ø±Ø¶ Batch Ù„Ù„ØªØ£ÙƒØ¯
inputs, classes = next(iter(dataloaders['train']))
out = torchvision.utils.make_grid(inputs)
imshow(out, title=[class_names[x] for x in classes])

# =============================
# 4ï¸âƒ£ Ø¯Ø§Ù„Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# =============================

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs_batch, labels in dataloaders[phase]:
                inputs_batch = inputs_batch.to(device)
                labels = labels.to(device)

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs_batch)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        optimizer.zero_grad()
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs_batch.size(0)
                running_corrects += torch.sum(preds == labels.data)

            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                phase, epoch_loss, epoch_acc))

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
        time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    model.load_state_dict(best_model_wts)
    return model

# =============================
# 5ï¸âƒ£ ConvNet as fixed feature extractor
# =============================

model_conv = models.resnet18(pretrained=True)
for param in model_conv.parameters():
    param.requires_grad = False  # ØªØ¬Ù…ÙŠØ¯ ÙƒÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª

num_ftrs = model_conv.fc.in_features
model_conv.fc = nn.Linear(num_ftrs, len(class_names))  # Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙÙ‚Ø· Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ù„Ù…
model_conv = model_conv.to(device)

criterion = nn.CrossEntropyLoss()
optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)
import torch
import torch.nn as nn
from torchvision import models

# Ù†ÙØªØ±Ø¶ Ø£Ù† model_conv Ù‡Ùˆ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¨Ø§Ù„ÙØ¹Ù„
# device Ù…Ø¹Ø±Ù Ù…Ø³Ø¨Ù‚Ù‹Ø§ (cuda Ø£Ùˆ cpu)
# class_names Ù…Ø¹Ø±Ù Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† ImageFolder

# =============================
# Ø­ÙØ¸ state_dict (Ø§Ù„Ù…Ø³ØªØ­Ø³Ù†)
# =============================
FILE_STATE = "model_conv_state.pth"
torch.save(model_conv.state_dict(), FILE_STATE)

# =============================
# Ù„ØªØ­Ù…ÙŠÙ„ state_dict Ù„Ø§Ø­Ù‚Ù‹Ø§
# =============================
# Ø¥Ù†Ø´Ø§Ø¡ Ù†ÙØ³ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_loaded = models.resnet18(pretrained=False)
num_ftrs = model_loaded.fc.in_features
model_loaded.fc = nn.Linear(num_ftrs, len(class_names))

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ state_dict
model_loaded.load_state_dict(torch.load(FILE_STATE, map_location=device))
model_loaded = model_loaded.to(device)
model_loaded.eval()  # ØªØ­ÙˆÙŠÙ„Ù‡ Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
import torch
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt

# =============================
# 1ï¸âƒ£ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„ØµÙˆØ±
# =============================
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# =============================
# 2ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø©
# =============================
def predict_image(image_path, model, class_names):
    image = Image.open(image_path).convert('RGB')
    input_tensor = preprocess(image).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(input_tensor)
        _, pred = torch.max(output, 1)
        class_name = class_names[pred.item()]
    return image, class_name

# =============================
# 3ï¸âƒ£ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
# =============================
img_path = "/content/drive/MyDrive/mosque.jpeg"  
image, class_name = predict_image(img_path, model, class_names)

plt.imshow(image)
plt.title(f"Predection {class_name}")
plt.axis('off')
plt.show()


ğŸ—‚ï¸ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
ğŸ“¦ robotak_al_siahi
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ model_conv_state.pth
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ static/
â”‚   â””â”€â”€ (Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©)
â”œâ”€â”€ train_model.ipynb
â””â”€â”€ README.md

ğŸ’¬ Ù…Ù„Ø§Ø­Ø¸Ø§Øª

ÙŠÙ…ÙƒÙ† Ø¨Ø³Ù‡ÙˆÙ„Ø© Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„ÙŠÙ…Ù†ÙŠØ© Ø¨Ø¥Ø¶Ø§ÙØ© ØµÙˆØ±Ù‡Ø§ ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.

ÙŠØ¯Ø¹Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ù† GPU Ùˆ CPU.

ÙŠÙ…ÙƒÙ† Ø¯Ù…Ø¬Ù‡ Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹ Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ø¬ÙˆØ§Ù„ Ø£Ùˆ Ø±ÙˆØ¨ÙˆØª Ù…ÙŠØ¯Ø§Ù†ÙŠ Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø³ÙŠØ§Ø­ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©.

ğŸ‘©â€ğŸ’» Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬Ø©

ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨ÙˆØ§Ø³Ø·Ø©:
Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙÙ‚ÙŠÙ‡ â€“ Asma Alfaqueeh
ğŸ“… Ø¹Ø§Ù… 2025
ğŸ’¬ Ù…Ø´Ø±ÙˆØ¹ "Ø±ÙˆØ¨ÙˆØªÙƒ Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ" Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠØ© ÙÙŠ Ø§Ù„ÙŠÙ…Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
